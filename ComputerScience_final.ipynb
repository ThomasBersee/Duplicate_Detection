{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpxKQN83Jp9V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZus9owYR_dE"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade xlrd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUuU9gvuR_vD"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('data_excel.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDI3vo2AST1D"
      },
      "outputs": [],
      "source": [
        "#function to get column\n",
        "def column(matrix, i):\n",
        "    return [row[i] for row in matrix]\n",
        "\n",
        "#jaccard similarity function\n",
        "def jaccard(x, y):\n",
        "  x_set = set(x)\n",
        "  y_set = set(y)\n",
        "  similarity = len(x_set.intersection(y_set)) / len(x_set.union(y_set))\n",
        "  return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtUWO7fdSbZN"
      },
      "outputs": [],
      "source": [
        "titles = (df['title'].str.lower())\n",
        "\n",
        "titles = titles.str.replace('inches', 'inch')\n",
        "titles = titles.str.replace('\"', 'inch')\n",
        "titles = titles.str.replace('-inch', 'inch')\n",
        "titles = titles.str.replace(' inch', 'inch')\n",
        "\n",
        "titles = titles.str.replace('Hertz', 'hz')\n",
        "titles = titles.str.replace('hertz', 'hz')\n",
        "titles = titles.str.replace('Hz', 'hz')\n",
        "titles = titles.str.replace('HZ', 'hz')\n",
        "titles = titles.str.replace(' hz', 'hz')\n",
        "titles = titles.str.replace('-hz', 'hz')\n",
        "titles = titles.str.replace('-', '')\n",
        "\n",
        "titles_list = list(titles)\n",
        "\n",
        "titles_word_list = [word for line in titles_list for word in line.split()]\n",
        "model_words = list()\n",
        "\n",
        "for word in titles_word_list:\n",
        "    z = re.match(\"[a-zA-Z0-9]*(([0-9]+[ˆ0-9, ]+)|([ˆ0-9, ]+[0-9]+))[a-zA-Z0-9]*\", word)\n",
        "    if z:\n",
        "        model_words.append(word)\n",
        "\n",
        "#remove duplicates\n",
        "model_words_set = set(model_words)\n",
        "#convert set back to a list\n",
        "model_words = list(model_words_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyNFS1q-VVnh"
      },
      "outputs": [],
      "source": [
        "def clean_titles(bootstrap):\n",
        "  titles = (bootstrap['title'].str.lower())\n",
        "\n",
        "  titles = titles.str.replace('inches', 'inch')\n",
        "  titles = titles.str.replace('\"', 'inch')\n",
        "  titles = titles.str.replace('-inch', 'inch')\n",
        "  titles = titles.str.replace(' inch', 'inch')\n",
        "\n",
        "  titles = titles.str.replace('Hertz', 'hz')\n",
        "  titles = titles.str.replace('hertz', 'hz')\n",
        "  titles = titles.str.replace('Hz', 'hz')\n",
        "  titles = titles.str.replace('HZ', 'hz')\n",
        "  titles = titles.str.replace(' hz', 'hz')\n",
        "  titles = titles.str.replace('-hz', 'hz')\n",
        "  titles = titles.str.replace('-', '')\n",
        "\n",
        "  return list(titles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTbtS1tJU8tb"
      },
      "outputs": [],
      "source": [
        "def df_to_matrix(df):\n",
        "  return df.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1x0COGfXxnv"
      },
      "outputs": [],
      "source": [
        "def binary_matrix(words: list, observations: list):\n",
        "    matrix = np.zeros((len(words), len(observations)))\n",
        "    for i in range(len(words)):\n",
        "        for j in range(len(observations)):\n",
        "            if words[i] in observations[j]:\n",
        "                matrix[i][j] = 1\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_HPqhzoX-Hh"
      },
      "outputs": [],
      "source": [
        "def rand_int_list(rows_signature: int):\n",
        "    integer_list = list()\n",
        "    for i in range(rows_signature):\n",
        "        random_int = random.randint(1, rows_signature)\n",
        "\n",
        "        while random_int in integer_list:\n",
        "            random_int = random.randint(1, rows_signature)\n",
        "\n",
        "        integer_list.append(random_int)\n",
        "    return integer_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGAbyV3jXzs3"
      },
      "outputs": [],
      "source": [
        "def signature_matrix(matrix, a: list, b: list, k: int, prime: int):\n",
        "    num_rows, num_cols = matrix.shape\n",
        "    signature = np.full((k, num_cols), 613)\n",
        "\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            if matrix[i][j] == 1:\n",
        "              for p in range(k):\n",
        "                    if ((a[p] + b[p] * i ) % prime) < signature[p][j]:\n",
        "                        signature[p][j] = ((a[p] + b[p] * i ) % prime)\n",
        "\n",
        "    return signature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXXUcLqjda8r"
      },
      "outputs": [],
      "source": [
        "def split_signature(signature, r):\n",
        "  length = len(signature)\n",
        "  b = math.floor(length/r)\n",
        "  split_sig = []\n",
        "  for i in range(0, length, r):\n",
        "    split_sig.append(signature[i : i+r])\n",
        "  return split_sig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rjqh6gFVexi6"
      },
      "outputs": [],
      "source": [
        "def LSH(matrix, r, n):\n",
        "  \n",
        "  b = math.floor(600/r)\n",
        "\n",
        "  buckets = []\n",
        "  column = 0 \n",
        "\n",
        "  for l in range(b):\n",
        "    buckets.append({})\n",
        "\n",
        "  for i in range(b):\n",
        "    column = 0\n",
        "    for j in range(n):\n",
        "      string = \"\"\n",
        "      for q in range(r):\n",
        "        string = string + str(matrix[i][q][j])\n",
        "      \n",
        "      if string not in buckets[i].keys():\n",
        "        buckets[i][string] = []\n",
        "      buckets[i][string].append(column)\n",
        "  \n",
        "      column = column + 1\n",
        "  \n",
        "  return buckets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hPSZX3Jg_qy"
      },
      "outputs": [],
      "source": [
        "def candidate_pairs(buckets, r, n):\n",
        "  candidate_matrix = np.zeros((n, n))\n",
        "  b = math.floor(600/r)\n",
        "  for i in range(b):\n",
        "    for key in buckets[i]:\n",
        "      if len(buckets[i].get(key)) > 1:\n",
        "        for j in range(len(buckets[i].get(key))-1):\n",
        "          for p in range(j+1, len(buckets[i].get(key))):\n",
        "            candidate_matrix[buckets[i].get(key)[j]][buckets[i].get(key)[p]] = 1\n",
        "                    \n",
        "\n",
        "  \n",
        "  return candidate_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFYUvMM7u8nz"
      },
      "outputs": [],
      "source": [
        "def performance(can_matrix, matrix, n):\n",
        "  pot_pairs = 0\n",
        "  total_pairs = 0\n",
        "  true_pos = 0\n",
        "\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      if can_matrix[i][j] == 1:\n",
        "        pot_pairs = pot_pairs + 1\n",
        "     \n",
        "        if matrix[i][0] == matrix[j][0]:\n",
        "          true_pos = true_pos + 1\n",
        "      \n",
        "  for i in range(n):\n",
        "    for j in range(i+1, n):\n",
        "      if matrix[i][0] == matrix[j][0]:\n",
        "        total_pairs = total_pairs + 1\n",
        "\n",
        "  pq = true_pos / pot_pairs\n",
        "  pc = true_pos/ total_pairs\n",
        "\n",
        "  F1_star = (2 * pq * pc) / (pq + pc)\n",
        "\n",
        "  fraq = pot_pairs / (n * (n-1) / 2)\n",
        "\n",
        "  return[true_pos, total_pairs, pot_pairs, pq, pc, F1_star, fraq ]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr_lZ23k4RN0"
      },
      "outputs": [],
      "source": [
        "def dissimilarity_matrix(can_matrix, matrix, signature, n):\n",
        "    \n",
        "  dis_matrix = np.full((n, n), 1000)\n",
        "\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      if can_matrix[i][j] == 1:\n",
        "\n",
        "        #check if candidates are from the same shop\n",
        "        if matrix[i][1] == matrix[j][1]:\n",
        "          dis_matrix[i][j] = 1000\n",
        "          dis_matrix[j][i] = 1000\n",
        "        #check if candidates are from the same brand\n",
        "        elif (matrix[i][54] == matrix[i][54] and matrix[j][54] == matrix[j][54]) and (matrix[i][54] != matrix[j][54]):\n",
        "          dis_matrix[i][j] = 1000\n",
        "          dis_matrix[j][i] = 1000\n",
        "        elif (matrix[i][26] == matrix[i][26] and matrix[j][26] == matrix[j][26]) and (matrix[i][26] != matrix[j][26]):\n",
        "          dis_matrix[i][j] = 1000\n",
        "          dis_matrix[j][i] = 1000\n",
        "        else:\n",
        "          #certain similiarity measure \n",
        "          dis_matrix[i][j] = 1 - jaccard(column(signature, i), column(signature, j))\n",
        "          dis_matrix[j][i] = 1 - jaccard(column(signature, i), column(signature, j))\n",
        "\n",
        "\n",
        "  return dis_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrOv16tT3DVz"
      },
      "outputs": [],
      "source": [
        "def cluster_algorithm(threshold, dissimilarity_matirx):\n",
        "  cluster = AgglomerativeClustering(n_clusters=None, affinity='precomputed', linkage='average', distance_threshold=threshold, compute_full_tree = True)\n",
        "  clusters = cluster.fit(dissimilarity_matirx)\n",
        "\n",
        "  pairs = []\n",
        "\n",
        "  for i in range(cluster.n_clusters_):\n",
        "  \n",
        "    no_products_cluster = len((np.where(cluster.labels_==i)[0]))\n",
        "    products_cluster = np.where(cluster.labels_==i)\n",
        "\n",
        "    if no_products_cluster > 1:\n",
        "      pairs = pairs + list(combinations(products_cluster[0], 2))\n",
        "\n",
        "  return pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn2B3cHIML6E"
      },
      "outputs": [],
      "source": [
        "def f1_performance(pairs, matrix, n):\n",
        "  true_pos = 0\n",
        "  false_pos = 0\n",
        "  false_neg = 0\n",
        "  total_pairs = 0\n",
        "\n",
        "  pot_pairs = len(pairs)\n",
        "\n",
        "  for i in range(len(pairs)):\n",
        "    if matrix[pairs[i][0]][0] ==  matrix[pairs[i][1]][0]:\n",
        "      true_pos = true_pos + 1\n",
        "    else:\n",
        "      false_pos = false_pos + 1\n",
        "\n",
        "  \n",
        "  for i in range(n):\n",
        "    for j in range(i+1, n):\n",
        "      if matrix[i][0] == matrix[j][0]:\n",
        "        total_pairs = total_pairs + 1\n",
        "  \n",
        "  false_neg = total_pairs - true_pos\n",
        "  \n",
        "\n",
        "\n",
        "  F1 = (2 * true_pos) / (2 * true_pos + false_pos + false_neg)\n",
        "\n",
        "  fraq = pot_pairs / (n * (n-1) / 2)\n",
        "\n",
        "  return F1, fraq "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjUAmnsHVGbZ"
      },
      "outputs": [],
      "source": [
        "def graph_results(df):\n",
        "\n",
        "  #get bootstrap\n",
        "\n",
        "  train = df.sample(n=1624, replace = True)\n",
        "  train = train.drop_duplicates()\n",
        "  train = train.sort_index(ascending=True)\n",
        "\n",
        "  test = pd.concat([df, train, train]).drop_duplicates(keep=False)\n",
        "\n",
        "  #clean titles\n",
        "\n",
        "  train_titles = clean_titles(train) \n",
        "\n",
        "  test_titles = clean_titles(test)\n",
        "\n",
        "  #convert dataframe to matrices \n",
        "\n",
        "  train_matrix = df_to_matrix(train)\n",
        "  \n",
        "  test_matrix = df_to_matrix(test)\n",
        "\n",
        "  #get sizes of train and test matrices\n",
        "\n",
        "  n_train, c_train = train_matrix.shape\n",
        "\n",
        "  n_test, c_test = test_matrix.shape\n",
        "\n",
        "  #create binary vectors \n",
        "\n",
        "  binary_train = binary_matrix(model_words, train_titles)\n",
        "\n",
        "  binary_test = binary_matrix(model_words, test_titles)\n",
        "\n",
        "  #create list of random int for minhash, k = 600 (signature matrix size)\n",
        "\n",
        "  k = 600\n",
        "\n",
        "  a_list = rand_int_list(k)\n",
        "  b_list = rand_int_list(k)\n",
        "\n",
        "  #create signature matrix, take large prime number\n",
        "\n",
        "  prime = 1283\n",
        "\n",
        "  signature_train = signature_matrix(binary_train, a_list, b_list, k, prime)\n",
        "\n",
        "  signature_test = signature_matrix(binary_test, a_list, b_list, k, prime)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  #loop over different values of r te get results for graphs over the test set\n",
        "\n",
        "  graph_results = []\n",
        "\n",
        "  for r in range(1, k, 1):\n",
        "\n",
        "    r_list = []\n",
        "\n",
        "    r_list.append(r)\n",
        "\n",
        "\n",
        "    #split signature matrix\n",
        "\n",
        "    split_test = split_signature(signature_test, r)\n",
        "\n",
        "    #do LSH\n",
        "\n",
        "    buckets_test = LSH(split_test, r, n_test)\n",
        "\n",
        "    #create candidate matrix\n",
        "\n",
        "    candidate_matrix_test = candidate_pairs(buckets_test, r, n_test)\n",
        "\n",
        "    r_list.append(performance(candidate_matrix_test, test_matrix, n_test))\n",
        "\n",
        "    graph_results.append(r_list)\n",
        "\n",
        "    print(r)\n",
        "\n",
        "  return [\"graph results\", [graph_results]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lpvmojeL9B_"
      },
      "outputs": [],
      "source": [
        "graph1 = graph_results(df)\n",
        "graph2 = graph_results(df)\n",
        "graph3 = graph_results(df)\n",
        "graph4 = graph_results(df)\n",
        "graph5 = graph_results(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIaZT4AOZDeH"
      },
      "source": [
        "bootstrap result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dhe09QgyZCQB"
      },
      "outputs": [],
      "source": [
        "def bootstrap_results(df):\n",
        "\n",
        "  #get bootstrap\n",
        "\n",
        "  train = df.sample(n=1624, replace = True)\n",
        "  train = train.drop_duplicates()\n",
        "  train = train.sort_index(ascending=True)\n",
        "\n",
        "  test = pd.concat([df, train, train]).drop_duplicates(keep=False)\n",
        "\n",
        "  #clean titles\n",
        "\n",
        "  train_titles = clean_titles(train) \n",
        "\n",
        "  test_titles = clean_titles(test)\n",
        "\n",
        "  #convert dataframe to matrices \n",
        "\n",
        "  train_matrix = df_to_matrix(train)\n",
        "  \n",
        "  test_matrix = df_to_matrix(test)\n",
        "\n",
        "  #get sizes of train and test matrices\n",
        "\n",
        "  n_train, c_train = train_matrix.shape\n",
        "\n",
        "  n_test, c_test = test_matrix.shape\n",
        "\n",
        "  #create binary vectors \n",
        "\n",
        "  binary_train = binary_matrix(model_words, train_titles)\n",
        "\n",
        "  binary_test = binary_matrix(model_words, test_titles)\n",
        "\n",
        "  #create list of random int for minhash, k = 600 (signature matrix size)\n",
        "\n",
        "  k = 600\n",
        "\n",
        "  a_list = rand_int_list(k)\n",
        "  b_list = rand_int_list(k)\n",
        "\n",
        "  #create signature matrix, take large prime number\n",
        "\n",
        "  prime = 1283\n",
        "\n",
        "  signature_train = signature_matrix(binary_train, a_list, b_list, k, prime)\n",
        "\n",
        "  signature_test = signature_matrix(binary_test, a_list, b_list, k, prime)\n",
        "\n",
        "  #print(\"preliminary done\")\n",
        "\n",
        "\n",
        "  #loop over different values of r to get f1 results over the training sample\n",
        "\n",
        "  training_results = []\n",
        "\n",
        "  for r in range(1, k, 1):\n",
        "\n",
        "    r_list = []\n",
        "\n",
        "    r_list.append(r)\n",
        "\n",
        "\n",
        "    #split signature matrix\n",
        "\n",
        "    split_training = split_signature(signature_train, r)\n",
        "\n",
        "    #print(\"training set is split\")\n",
        "\n",
        "    #do LSH\n",
        "\n",
        "    buckets_training = LSH(split_training, r, n_train)\n",
        "\n",
        "    #print(\"buckets are made\")\n",
        "\n",
        "    #create candidate matrix\n",
        "\n",
        "    candidate_matrix_training = candidate_pairs(buckets_training, r, n_train)\n",
        "\n",
        "    #print(\"candidate matrix is done\")\n",
        "\n",
        "    #create dissimilarity matrix \n",
        "\n",
        "    dis_matrix = dissimilarity_matrix(candidate_matrix_training, train_matrix, signature_train, n_train)\n",
        "\n",
        "    #print(\"dissimilarity matrix is made\")\n",
        "\n",
        "    #loop over values of the threshold\n",
        "\n",
        "    print(\"now optimize for\")  \n",
        "    print(r)\n",
        "\n",
        "\n",
        "    for j in np.arange(50, 1000, 50):\n",
        "\n",
        "      print(r)\n",
        "      print(j)\n",
        "\n",
        "      j_list = []\n",
        "\n",
        "      j_list.append(j)\n",
        "\n",
        "      pairs = cluster_algorithm(j, dis_matrix)\n",
        "\n",
        "      F1 = f1_performance(pairs, train_matrix, n_train)\n",
        "\n",
        "      j_list.append(F1)\n",
        "\n",
        "      r_list.append(j_list)\n",
        "    \n",
        "\n",
        "    training_results.append(r_list)\n",
        "\n",
        "  return training_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7dVqlGaiXRg"
      },
      "outputs": [],
      "source": [
        "bootstrap1 = bootstrap_results(df)\n",
        "bootstrap2 = bootstrap_results(df)\n",
        "bootstrap3 = bootstrap_results(df)\n",
        "bootstrap4 = bootstrap_results(df)\n",
        "bootstrap5 = bootstrap_results(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SauwWz_TjIX5"
      },
      "source": [
        "function to find best thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNeRxXVqj3Ch"
      },
      "outputs": [],
      "source": [
        "def average_thresholds(list1, list2, list3, list4, list5):\n",
        "  average_results = []\n",
        "\n",
        "  for i in range(len(list1)):\n",
        "\n",
        "    results = []\n",
        "\n",
        "\n",
        "    for j in range(1, 20, 1):     \n",
        "\n",
        "      #results.append(list1[i][0])\n",
        "\n",
        "      total_f1 = list1[i][j][1][0] + list2[i][j][1][0] + list3[i][j][1][0] + list4[i][j][1][0] + list5[i][j][1][0]\n",
        "      average_f1 = total_f1 / 5\n",
        "\n",
        "      results.append(list1[i][j][0])\n",
        "      results.append(average_f1)\n",
        "\n",
        "    average_results.append(results)\n",
        "  \n",
        "  return average_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqXH22M-qMYS"
      },
      "outputs": [],
      "source": [
        "def selecting_thresholds(antwoorden):\n",
        "  best_thresholds = []\n",
        "  for i in range(len(antwoorden)):\n",
        "    best_threshold = antwoorden[i][1]\n",
        "    index = 1\n",
        "\n",
        "    for j in range(3, 38, 2):\n",
        "\n",
        "      if antwoorden[i][j] > best_threshold:\n",
        "        best_threshold = antwoorden[i][j]\n",
        "        index = j\n",
        "     \n",
        "      \n",
        "    \n",
        "    best_thresholds.append(antwoorden[i][index - 1])\n",
        "  return best_thresholds\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xki_xqR9zvdb"
      },
      "outputs": [],
      "source": [
        "average_results = average_thresholds(bootstrap1, bootstrap2, bootstrap3, bootstrap4, bootstrap5)\n",
        "best_thresholds = selecting_thresholds(average_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtpnhIC-fRTB"
      },
      "outputs": [],
      "source": [
        "def test_results(df, optimal_thresholds):\n",
        "  \n",
        "  #get bootstrap\n",
        "\n",
        "  train = df.sample(n=1624, replace = True)\n",
        "  train = train.drop_duplicates()\n",
        "  train = train.sort_index(ascending=True)\n",
        "\n",
        "  test = pd.concat([df, train, train]).drop_duplicates(keep=False)\n",
        "\n",
        "  #clean titles\n",
        "\n",
        "  train_titles = clean_titles(train) \n",
        "\n",
        "  test_titles = clean_titles(test)\n",
        "\n",
        "  #convert dataframe to matrices \n",
        "\n",
        "  train_matrix = df_to_matrix(train)\n",
        "  \n",
        "  test_matrix = df_to_matrix(test)\n",
        "\n",
        "  #get sizes of train and test matrices\n",
        "\n",
        "  n_train, c_train = train_matrix.shape\n",
        "\n",
        "  n_test, c_test = test_matrix.shape\n",
        "\n",
        "  #create binary vectors \n",
        "\n",
        "  binary_train = binary_matrix(model_words, train_titles)\n",
        "\n",
        "  binary_test = binary_matrix(model_words, test_titles)\n",
        "\n",
        "  #create list of random int for minhash, k = 600 (signature matrix size)\n",
        "\n",
        "  k = 600\n",
        "\n",
        "  a_list = rand_int_list(k)\n",
        "  b_list = rand_int_list(k)\n",
        "\n",
        "  #create signature matrix, take large prime number\n",
        "\n",
        "  prime = 1283\n",
        "\n",
        "  signature_train = signature_matrix(binary_train, a_list, b_list, k, prime)\n",
        "\n",
        "  signature_test = signature_matrix(binary_test, a_list, b_list, k, prime)\n",
        "\n",
        "  print(\"preliminary done\")\n",
        "\n",
        "\n",
        "  #loop over different values of r to get f1 results over the training sample\n",
        "\n",
        "  test_results = []\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  for r in range(1, k, 1):\n",
        "\n",
        "    r_list = []\n",
        "\n",
        "    r_list.append(r)\n",
        "\n",
        "\n",
        "    #split signature matrix\n",
        "\n",
        "    split_test = split_signature(signature_test, r)\n",
        "\n",
        "    print(\"test set is split\")\n",
        "\n",
        "    #do LSH\n",
        "\n",
        "    buckets_test = LSH(split_test, r, n_test)\n",
        "\n",
        "    print(\"buckets are made\")\n",
        "\n",
        "    #create candidate matrix\n",
        "\n",
        "    candidate_matrix_test = candidate_pairs(buckets_test, r, n_test)\n",
        "\n",
        "    print(\"candidate matrix is done\")\n",
        "\n",
        "    #create dissimilarity matrix \n",
        "\n",
        "    dis_matrix = dissimilarity_matrix(candidate_matrix_test, test_matrix, signature_test, n_test)\n",
        "\n",
        "    print(\"dissimilarity matrix is made\")\n",
        "\n",
        "    #get optimal threshold\n",
        "\n",
        "    j = optimal_thresholds[i]\n",
        "\n",
        "    pairs = cluster_algorithm(j, dis_matrix)\n",
        "\n",
        "    print(pairs)\n",
        "\n",
        "    F1 = f1_performance(pairs, test_matrix, n_test)\n",
        "\n",
        "    r_list.append(F1)\n",
        "\n",
        "    test_results.append(r_list)\n",
        "\n",
        "    i = i + 1\n",
        "\n",
        "  return test_results\n",
        "\n",
        "  \n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_bP925qvAZz"
      },
      "outputs": [],
      "source": [
        "final1 = test_results(df, best_thresholds)\n",
        "final2 = test_results(df, best_thresholds)\n",
        "final3 = test_results(df, best_thresholds)\n",
        "final4 = test_results(df, best_thresholds)\n",
        "final5 = test_results(df, best_thresholds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0A4O468R2mN"
      },
      "source": [
        "GRAPHING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCNjdphD7U9u"
      },
      "outputs": [],
      "source": [
        "def average_f1(final1, final2, final3, final4, final5):\n",
        "    average = []\n",
        "    for i in range(1, 38, 1):\n",
        "      sum = 0\n",
        "      sum = sum + final1[i][1][0] + final2[i][1][0]  + final3[i][1][0]  + final4[i][1][0]  + final5[i][1][0] \n",
        "      av = sum / 5\n",
        "      average.append(av)\n",
        "\n",
        "    return average\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY_QIFvRLOr4"
      },
      "outputs": [],
      "source": [
        "def average_completeness(graph1, graph2, graph3, graph4, graph5):\n",
        "  average = []\n",
        "  for i in range(599):\n",
        "    sum = 0\n",
        "    sum = sum + graph1[1][0][i][1][4] + graph2[1][0][i][1][4]  + graph3[1][0][i][1][4]  + graph4[1][0][i][1][4]  + graph5[1][0][i][1][4] \n",
        "    av = sum / 5\n",
        "    average.append(av)\n",
        "\n",
        "  return average\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average_f1star(graph1, graph2, graph3, graph4, graph5):\n",
        "  average = []\n",
        "  for i in range(599):\n",
        "    sum = 0\n",
        "    sum = sum + graph1[1][0][i][1][5] + graph2[1][0][i][1][5]  + graph3[1][0][i][1][5]  + graph4[1][0][i][1][5]  + graph5[1][0][i][1][5] \n",
        "    av = sum / 5\n",
        "    average.append(av)\n",
        "\n",
        "  return average\n",
        "  "
      ],
      "metadata": {
        "id": "CY1ei5oZkbxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yXMILKnNv_d"
      },
      "outputs": [],
      "source": [
        "def average_quality(graph1, graph2, graph3, graph4, graph5):\n",
        "  average = []\n",
        "  for i in range(599):\n",
        "    sum = 0\n",
        "    sum = sum + graph1[1][0][i][1][3] + graph2[1][0][i][1][3]  + graph3[1][0][i][1][3]  + graph4[1][0][i][1][3]  + graph5[1][0][i][1][3] \n",
        "    av = sum / 5\n",
        "    average.append(av)\n",
        "\n",
        "  return average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSskbxmI_Lth"
      },
      "outputs": [],
      "source": [
        "pair_completeness = average_completeness(graph1, graph2, graph3, graph4, graph5)\n",
        "\n",
        "for i in range(599):\n",
        "  x.append(graph1[1][0][i][1][6])\n",
        " \n",
        "plt.plot(x, pair_completeness, color=\"black\")\n",
        "\n",
        "\n",
        "# naming the x axis\n",
        "plt.xlabel('fraction of comparisons')\n",
        "# naming the y axis\n",
        "plt.ylabel('pair completeness')\n",
        "plt.legend()\n",
        "# giving a title to my graph\n",
        "plt.title('')\n",
        "\n",
        "\n",
        "# function to show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1star = average_f1star(graph1, graph2, graph3, graph4, graph5)\n",
        "\n",
        "for i in range(2, 20, 1):\n",
        "  x.append(graph1[1][0][i][1][6])\n",
        "\n",
        "plt.plot(x, f1star, color=\"black\")\n",
        "\n",
        "\n",
        "# naming the x axis\n",
        "plt.xlabel('fraction of comparisons')\n",
        "# naming the y axis\n",
        "plt.ylabel('f1*')\n",
        "plt.legend()\n",
        "# giving a title to my graph\n",
        "plt.title('')\n",
        "\n",
        "\n",
        "# function to show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SX8wHvKBlWpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rOiw4oHKUjw"
      },
      "outputs": [],
      "source": [
        "pair_quality = average_quality(graph1, graph2, graph3, graph4, graph5)\n",
        "\n",
        "for i in range(599):\n",
        "  x.append(graph1[1][0][i][1][6])\n",
        " \n",
        "plt.plot(x, pair_quality, color=\"black\", label=\"pair quality\")\n",
        "\n",
        "\n",
        "# naming the x axis\n",
        "plt.xlabel('fraction of comparisons')\n",
        "# naming the y axis\n",
        "plt.ylabel('pair quality')\n",
        "plt.legend()\n",
        "# giving a title to my graph\n",
        "plt.title('')\n",
        "\n",
        "\n",
        "# function to show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2eq8KJK8UBH"
      },
      "outputs": [],
      "source": [
        "f1 = average_f1(bootstrap1, bootstrap2, bootstrap3, bootstrap4, bootstrap5)\n",
        "\n",
        "for i in range(1, 37, 1):\n",
        "  x.append(graph1[1][0][i][1][6])\n",
        "  \n",
        " \n",
        "print(x[20])\n",
        "plt.plot(x, f1, color=\"black\")\n",
        "\n",
        "\n",
        "# naming the x axis\n",
        "plt.xlabel('fraction of comparisons')\n",
        "# naming the y axis\n",
        "plt.ylabel('f1')\n",
        "plt.legend()\n",
        "# giving a title to my graph\n",
        "plt.title('')\n",
        "\n",
        "\n",
        "# function to show the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}